Loading trainer: DPT
Loading dataset: BraTS20
Reading split from /home/bheeshmsharma/Karthikeyan/Public/RASALoRE-2025/DATA/BraTS20/split_brats20.json
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  -------
Dataset    BraTS20
# classes  2
# train_x  2
# test     0
---------  -------
Loading CLIP (backbone: ViT-B/32)
Building custom CLIP VPT Deep
Turning off gradients in both the image and the text encoder
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/BraTS20/tensorboard)
epoch [1/60] batch [1/1] time 0.937 (0.937) data 0.213 (0.213) loss 1.6279 (1.6279) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:55
epoch [2/60] batch [1/1] time 0.435 (0.435) data 0.159 (0.159) loss 1.7617 (1.7617) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:25
epoch [3/60] batch [1/1] time 0.363 (0.363) data 0.148 (0.148) loss 1.6377 (1.6377) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:20
epoch [4/60] batch [1/1] time 0.366 (0.366) data 0.149 (0.149) loss 1.8125 (1.8125) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:20
epoch [5/60] batch [1/1] time 0.409 (0.409) data 0.150 (0.150) loss 1.6650 (1.6650) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:22
epoch [6/60] batch [1/1] time 0.388 (0.388) data 0.152 (0.152) loss 1.8887 (1.8887) acc 0.0000 (0.0000) lr 1.0000e-05 eta 0:00:20
epoch [7/60] batch [1/1] time 0.431 (0.431) data 0.188 (0.188) loss 1.6738 (1.6738) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:22
epoch [8/60] batch [1/1] time 0.412 (0.412) data 0.156 (0.156) loss 1.6240 (1.6240) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:21
epoch [9/60] batch [1/1] time 0.416 (0.416) data 0.167 (0.167) loss 1.8037 (1.8037) acc 50.0000 (50.0000) lr 1.0000e-05 eta 0:00:21
epoch [10/60] batch [1/1] time 0.394 (0.394) data 0.158 (0.158) loss 1.7139 (1.7139) acc 50.0000 (50.0000) lr 1.0000e-02 eta 0:00:19
epoch [11/60] batch [1/1] time 0.440 (0.440) data 0.210 (0.210) loss 1.7646 (1.7646) acc 50.0000 (50.0000) lr 9.9931e-03 eta 0:00:21
epoch [12/60] batch [1/1] time 0.413 (0.413) data 0.159 (0.159) loss 2.0488 (2.0488) acc 50.0000 (50.0000) lr 9.9726e-03 eta 0:00:19
epoch [13/60] batch [1/1] time 0.400 (0.400) data 0.156 (0.156) loss 1.8535 (1.8535) acc 50.0000 (50.0000) lr 9.9384e-03 eta 0:00:18
epoch [14/60] batch [1/1] time 0.389 (0.389) data 0.160 (0.160) loss 1.8545 (1.8545) acc 50.0000 (50.0000) lr 9.8907e-03 eta 0:00:17
epoch [15/60] batch [1/1] time 0.393 (0.393) data 0.153 (0.153) loss 1.4893 (1.4893) acc 100.0000 (100.0000) lr 9.8296e-03 eta 0:00:17
epoch [16/60] batch [1/1] time 0.427 (0.427) data 0.195 (0.195) loss 1.7979 (1.7979) acc 50.0000 (50.0000) lr 9.7553e-03 eta 0:00:18
epoch [17/60] batch [1/1] time 0.427 (0.427) data 0.157 (0.157) loss 2.2031 (2.2031) acc 50.0000 (50.0000) lr 9.6679e-03 eta 0:00:18
epoch [18/60] batch [1/1] time 0.414 (0.414) data 0.168 (0.168) loss 1.4756 (1.4756) acc 50.0000 (50.0000) lr 9.5677e-03 eta 0:00:17
epoch [19/60] batch [1/1] time 0.410 (0.410) data 0.150 (0.150) loss 1.8740 (1.8740) acc 50.0000 (50.0000) lr 9.4550e-03 eta 0:00:16
epoch [20/60] batch [1/1] time 0.430 (0.430) data 0.173 (0.173) loss 2.0195 (2.0195) acc 50.0000 (50.0000) lr 9.3301e-03 eta 0:00:17
epoch [21/60] batch [1/1] time 0.403 (0.403) data 0.148 (0.148) loss 2.0488 (2.0488) acc 50.0000 (50.0000) lr 9.1934e-03 eta 0:00:15
epoch [22/60] batch [1/1] time 0.420 (0.420) data 0.159 (0.159) loss 1.6992 (1.6992) acc 50.0000 (50.0000) lr 9.0451e-03 eta 0:00:15
epoch [23/60] batch [1/1] time 0.409 (0.409) data 0.143 (0.143) loss 1.6406 (1.6406) acc 50.0000 (50.0000) lr 8.8857e-03 eta 0:00:15
epoch [24/60] batch [1/1] time 0.430 (0.430) data 0.179 (0.179) loss 2.0117 (2.0117) acc 0.0000 (0.0000) lr 8.7157e-03 eta 0:00:15
epoch [25/60] batch [1/1] time 0.421 (0.421) data 0.164 (0.164) loss 1.5723 (1.5723) acc 50.0000 (50.0000) lr 8.5355e-03 eta 0:00:14
epoch [26/60] batch [1/1] time 0.409 (0.409) data 0.163 (0.163) loss 1.7383 (1.7383) acc 50.0000 (50.0000) lr 8.3457e-03 eta 0:00:13
epoch [27/60] batch [1/1] time 0.417 (0.417) data 0.168 (0.168) loss 1.6953 (1.6953) acc 50.0000 (50.0000) lr 8.1466e-03 eta 0:00:13
epoch [28/60] batch [1/1] time 0.401 (0.401) data 0.154 (0.154) loss 1.7314 (1.7314) acc 50.0000 (50.0000) lr 7.9389e-03 eta 0:00:12
epoch [29/60] batch [1/1] time 0.399 (0.399) data 0.159 (0.159) loss 1.7227 (1.7227) acc 50.0000 (50.0000) lr 7.7232e-03 eta 0:00:12
epoch [30/60] batch [1/1] time 0.416 (0.416) data 0.161 (0.161) loss 1.7266 (1.7266) acc 50.0000 (50.0000) lr 7.5000e-03 eta 0:00:12
epoch [31/60] batch [1/1] time 0.385 (0.385) data 0.167 (0.167) loss 0.8975 (0.8975) acc 50.0000 (50.0000) lr 7.2700e-03 eta 0:00:11
epoch [32/60] batch [1/1] time 0.369 (0.369) data 0.162 (0.162) loss 0.9341 (0.9341) acc 100.0000 (100.0000) lr 7.0337e-03 eta 0:00:10
epoch [33/60] batch [1/1] time 0.400 (0.400) data 0.185 (0.185) loss 0.9170 (0.9170) acc 50.0000 (50.0000) lr 6.7918e-03 eta 0:00:10
epoch [34/60] batch [1/1] time 0.368 (0.368) data 0.167 (0.167) loss 0.9009 (0.9009) acc 50.0000 (50.0000) lr 6.5451e-03 eta 0:00:09
epoch [35/60] batch [1/1] time 0.363 (0.363) data 0.165 (0.165) loss 0.9209 (0.9209) acc 50.0000 (50.0000) lr 6.2941e-03 eta 0:00:09
epoch [36/60] batch [1/1] time 0.371 (0.371) data 0.164 (0.164) loss 0.9014 (0.9014) acc 50.0000 (50.0000) lr 6.0396e-03 eta 0:00:08
epoch [37/60] batch [1/1] time 0.358 (0.358) data 0.162 (0.162) loss 0.9028 (0.9028) acc 50.0000 (50.0000) lr 5.7822e-03 eta 0:00:08
epoch [38/60] batch [1/1] time 0.347 (0.347) data 0.150 (0.150) loss 0.9092 (0.9092) acc 100.0000 (100.0000) lr 5.5226e-03 eta 0:00:07
epoch [39/60] batch [1/1] time 0.379 (0.379) data 0.160 (0.160) loss 0.9087 (0.9087) acc 50.0000 (50.0000) lr 5.2617e-03 eta 0:00:07
epoch [40/60] batch [1/1] time 0.407 (0.407) data 0.198 (0.198) loss 0.8975 (0.8975) acc 50.0000 (50.0000) lr 5.0000e-03 eta 0:00:08
epoch [41/60] batch [1/1] time 0.382 (0.382) data 0.168 (0.168) loss 0.9033 (0.9033) acc 50.0000 (50.0000) lr 4.7383e-03 eta 0:00:07
epoch [42/60] batch [1/1] time 0.367 (0.367) data 0.160 (0.160) loss 0.8809 (0.8809) acc 50.0000 (50.0000) lr 4.4774e-03 eta 0:00:06
epoch [43/60] batch [1/1] time 0.375 (0.375) data 0.158 (0.158) loss 0.9004 (0.9004) acc 50.0000 (50.0000) lr 4.2178e-03 eta 0:00:06
epoch [44/60] batch [1/1] time 0.356 (0.356) data 0.156 (0.156) loss 0.9121 (0.9121) acc 50.0000 (50.0000) lr 3.9604e-03 eta 0:00:05
epoch [45/60] batch [1/1] time 0.360 (0.360) data 0.153 (0.153) loss 0.9028 (0.9028) acc 50.0000 (50.0000) lr 3.7059e-03 eta 0:00:05
epoch [46/60] batch [1/1] time 0.367 (0.367) data 0.154 (0.154) loss 0.9268 (0.9268) acc 50.0000 (50.0000) lr 3.4549e-03 eta 0:00:05
epoch [47/60] batch [1/1] time 0.349 (0.349) data 0.147 (0.147) loss 0.9043 (0.9043) acc 50.0000 (50.0000) lr 3.2082e-03 eta 0:00:04
epoch [48/60] batch [1/1] time 0.376 (0.376) data 0.163 (0.163) loss 0.9033 (0.9033) acc 50.0000 (50.0000) lr 2.9663e-03 eta 0:00:04
epoch [49/60] batch [1/1] time 0.371 (0.371) data 0.155 (0.155) loss 0.9219 (0.9219) acc 50.0000 (50.0000) lr 2.7300e-03 eta 0:00:04
epoch [50/60] batch [1/1] time 0.374 (0.374) data 0.165 (0.165) loss 0.9043 (0.9043) acc 50.0000 (50.0000) lr 2.5000e-03 eta 0:00:03
epoch [51/60] batch [1/1] time 0.370 (0.370) data 0.151 (0.151) loss 0.8882 (0.8882) acc 50.0000 (50.0000) lr 2.2768e-03 eta 0:00:03
epoch [52/60] batch [1/1] time 0.378 (0.378) data 0.169 (0.169) loss 0.9043 (0.9043) acc 50.0000 (50.0000) lr 2.0611e-03 eta 0:00:03
epoch [53/60] batch [1/1] time 0.369 (0.369) data 0.152 (0.152) loss 0.9092 (0.9092) acc 50.0000 (50.0000) lr 1.8534e-03 eta 0:00:02
epoch [54/60] batch [1/1] time 0.355 (0.355) data 0.151 (0.151) loss 0.9004 (0.9004) acc 50.0000 (50.0000) lr 1.6543e-03 eta 0:00:02
epoch [55/60] batch [1/1] time 0.360 (0.360) data 0.156 (0.156) loss 0.8994 (0.8994) acc 100.0000 (100.0000) lr 1.4645e-03 eta 0:00:01
epoch [56/60] batch [1/1] time 0.362 (0.362) data 0.169 (0.169) loss 0.9023 (0.9023) acc 50.0000 (50.0000) lr 1.2843e-03 eta 0:00:01
epoch [57/60] batch [1/1] time 0.373 (0.373) data 0.165 (0.165) loss 0.9097 (0.9097) acc 50.0000 (50.0000) lr 1.1143e-03 eta 0:00:01
epoch [58/60] batch [1/1] time 0.375 (0.375) data 0.165 (0.165) loss 0.9082 (0.9082) acc 50.0000 (50.0000) lr 9.5492e-04 eta 0:00:00
epoch [59/60] batch [1/1] time 0.399 (0.399) data 0.189 (0.189) loss 0.9019 (0.9019) acc 50.0000 (50.0000) lr 8.0665e-04 eta 0:00:00
epoch [60/60] batch [1/1] time 0.350 (0.350) data 0.155 (0.155) loss 0.9072 (0.9072) acc 50.0000 (50.0000) lr 6.6987e-04 eta 0:00:00
Checkpoint saved to output/BraTS20/image_encoder.transformer.ctx_learner/model.pth.tar-60
Checkpoint saved to output/BraTS20/image_encoder.transformer.extractor/model.pth.tar-60
Checkpoint saved to output/BraTS20/prompt_learner/model.pth.tar-60
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
